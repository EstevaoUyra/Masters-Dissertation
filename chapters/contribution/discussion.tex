\chapter{Discussion}
\label{chap:results}

\section{Methodology}
How does the neural activity changes with learning is still an open question, and methods that enable this question to be posed in a systematic manner are currently in development. In the experiment presented here, the central concern was the task to be easy enough so that learning could occur in a single session, allowing authentic comparison between a single population of neurons during distinct behavior patterns. This concern was accomplished, as animals indeed learn in a single session, enough to change perceptively their response times, and thus receive more rewards. 

We expect changes in neural activity to reflect changes in behavior--actually with causality going the opposite direction. Moreover, we suppose activity will change similarly in different animals, implicitly assuming that animals employ the same strategies, at least with respect to time representation. The behavioral responses found here do not provide support for this assumption, since both the rolling mean and structure of peak responses are highly variable, but since these differences can also originate on the decision making, motor execution, or strategy of learning, they do not imply different strategies of time representation.

To avoid biasing our analysis with motor activity we epoched data before estimating the firing rate, removing the beginning and ending, and had to choose appropriate methods to padding the timeseries in order to keep the borders. Analysis of Mahalanobis similarity in the neural activity didn't show huge effects at these borders, and we kept our analysis with the firing rates. 

Calculating the similarity matrix using Mahalanobis distances has some benefits in comparison to using classifiers. Firstly, it is gives a much more direct measure of distance, due to its simplicity. Secondly, it doesn't interferes on information about two timepoints because of a third one, a feature of classifier's probability matrices. On the other hand, since it uses all dimensions to calculate the distance, it is more prone to confounding effects due to multiplexing \cite{gu2015oscillatory}. The similarity matrix can nevertheless be used as a tool for assessing the data and preprocessing steps, before going on to more powerful analysis. In figure \ref{fig:mahalanobis_smoothing}, we saw that without smoothing, there doesn't seem to be any consistent activity in subject 10 when we use a time window of 10ms, but there surely is in the 100ms window. This points out that signal-to-noise ratio is too low in the former case, and that we should use the bigger window instead. % It is also possible to see the similarity near the borders increases specially when the smoothing is larger, which may signal to an artifact of the smoothing process.

Decoding of activity is not specific to the classifier in question, and the differences in classifier performance are expected. The two better ranked classifiers were the Gradient Boosting Machines, the most widely applied classifiers in Kaggle competitions \cite{chen2016xgboost, ke2017lightgbm}. Logistic Regression results were similar enough to the Gradient Boosting, so that we chose to continue analysis using Logistic Regression, given that it is a much simpler and faster classifier.

\section{Contribution}
When we compared the classification performances during naivety and proficiency phases, we found distinct evolution patterns in the mPFC and Striatum, with only the latter agreeing to our initial hypothesis. Experimental inactivation of the mPFC in this task, performed afterwards by our research group, has shown impairment only during learning, and not during performance of proficient animals (Chiuffa et al., in preparation). This finding supports the idea of an initial involvement of the mPFC that later decreases or vanishes. 

While time is understood as an essential dimension for learning associations \cite{balsam2009temporal,kirkpatrick2016associative}, it may actually be either an attribute encoded in the associations \cite{molet2014timing} or a precursor to the learning of associations \cite{balsam2002timing}. Our original hypothesis is in line with the first case, as we expected time representations to develop during learning, and we found the activity in the Striatum to be consistent with this statement. On the other hand, our results for the mPFC are more closely in line with the precursor idea \cite{balsam2002timing}, because time representation seems to be present even when the performance at the task is poor. 

The Striatum has been already implicated in associative learning \cite{li2011differential,liljeholm2012contributions}, specially in the performance of overlearned behaviors \cite{smith2013dual}. Complementarily, optogenetic stimulation of the mPFC suffices to learn associations such as Eye Blink Conditioning \cite{wu2015optogenetic}, and its ensemble activity encodes relevant cues after rewards \cite{maggi2018ensemble}. While disruption of PFC's dopamine receptors impairs associative learning in some tasks, it does not impair performance of learned associations \cite{puig2012role, puig2014prefrontal}, even though learning induces lasting changes in the mPFC's responses to related stimuli \cite{takehara2008spontaneous}.

The mPFC has been shown to encode only task-relevant information during learning \cite{kaplan2017role}, and in some studies it has been shown to decrease this encoding after learning \cite{schuck2015medial}, in agreement with our results. The importance of the cortex for learning but not for execution has been shown also in the motor cortex \cite{kawai2015motor}, and it motivates a model where the cortex "tutors" the Striatum, which is the responsible for performance after learning \cite{murray2017learning}. The opposite has been shown in other tasks \cite{pasupathy2005different}, where activity in the Striatum predicts response faster than the PFC, motivating a model where the basal ganglia is the one who provides the reinforcement signals to the cortex \cite{helie2015learning}. 

Studies on the corticostriatal role in decision making have already proposed the coexistence of two heterogeneous learning processes \cite{balleine1998goal, balleine2007role, smith2013dual}: one of them consists of an automatic/habitual Stimulus-Response learning, strengthened by reinforcers, while the other reflects a goal-directed/flexible Response-Outcome learning \cite{dickinson2015instrumental}. The neurobiological substrates of these two processes have been dissociated, wherein the goal-directed being dependent on dmPFC and dorsal Striatum, and the automatic being dependent on vmPFC and ventral Striatum \cite{dickinson2015instrumental}. Importantly, the relative contribution of these two forms of learning is dependent on the reinforcement schedule, in addition to the complexity of the task \cite{dickinson2015instrumental}. 

Studies on the vmPFC's importance to learning, in the field of fear extinction, point out to its role in retaining learning \cite{phelps2004extinction}, while it seems necessary to performance in gambling tasks \cite{rogalsky2012risky}. Distinctly, dmPFC's role has been verified to bolster learning but not performance \cite{balleine2007still}, mirroring the mPFC results from our group.

Through the instrumental learning lens, it seems that learning in our DRRD task is dominated by the goal-directed system. Accordingly, in a T-Maze task, initial performance was also found to be dominated by the goal-directed system, and flexible to changes in rewards, whereas overtraining made the performance resistant to reward devaluation and dominated by habit \cite{smith2013dual}. In contrast, other interval timing tasks, using the same time scale as ours, are still dependent on the mPFC even after 10 learning sessions \cite{narayanan2006reversible}. This difference can be expected in instrumental learning if either their task is more complex than ours, or their reinforcement schedule is more reliable than ours \cite{dickinson2015instrumental}. Neither option provides a clear explanation, since comparisons are not straightforward, and we remain lacking an integrative framework for time learning.

% This provides us with testable hypothesis, based on the 

% The dissociation between timing and other aspects of behavior is a constant challenge in the present day \cite{kirkpatrick2016associative}.

%Reinforcement learning theories are central to the current understanding of learning processes and decision making in general, specially in the presence of rewards \cite{dayan2008decision, dohmatob2017dark, niv2016reinforcement}, and the PFC and Striatum are key areas in this framework \cite{dayan2008decision}, the PFC in relation to the , and the striatum 

%The representation of all the world's complexity into an well defined state space is essential to reinforcement learning \cite{mnih2015human}, and when information is not observable, the representation of the task state is supposed to be the role of the OFC \cite{wilson2014orbitofrontal}. The OFC may encode state information even when it is not important for behavior, and is proposed to disambiguate between task states that are perceptually similar but conceptually different, by encoding information about hidden variables \cite{schuck2016human}. While some state variables may be accounted for in other areas of the brain, non-observable task information may have their encoding only at the OFC, as shown in experimental works where a rats responded normally to tasks with explicit-signaled states, but showed deficits when task states were unobservable \cite{wikenheiser2016over}. In Reversal Learning and Delaying Alternation tasks, a Reinforcement Learning algorithm with a single state has similar results to OFC damaged rats \cite{wilson2014orbitofrontal}.

% niv2016reinforcement

% Time may be represented in the brain in the form of temporal maps \cite{kirkpatrick2016associative, fernandes2017episodic}, and its appearance in behavior 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% It is common in the timing literature to expect the same brain regions to represent time in different tasks, given that the size of the interval is the same \cite{}. We expected, accordingly, to find results coherent to those in previous studies with the same interval size \cite{}, in which PFC activity was necessary to correct behavior. 
\section{Limitations}
It is common to 1) equate a classifier's performance with the presence of information in the neural activity, and even further to 2) believe that if information is present, then the animal has access to it  \cite{king2014characterizing}. 

Firstly, the classifier's performance is not equal to the presence of information, it only \textit{implies} the information, meaning that the absence of prediction is possible even when there is information in the neural activity, for instance when the classifier is too strongly regularized. In the case that a classifier has been carefully tuned, and even so remained with a poor performance, we still have no way of knowing whether the region truly lacks information, or if information is concealed in hidden states such as presynaptic sensitivity, or internal states of the cells. Most of our discussion rests upon the implicit assumption that the only representation that is of interest to us is the neuronal activity, whilst changes in decoder performance could also be explained as representation shifts from activity states to hidden states, without entailing representation decay. 
% although if we compare the same set of cells through time, we can have increased confidence in activity \textit{changes} and \textit{comparisons}.

Secondly, classifiers can be powerful enough to extract meaning from information in a raw form, that will still be processed downstream \cite{king2014characterizing}. As an example, if we record enough cells from the primary visual cortex, we may be able to decode, given a strong classifier, the identity of different objects being seen, an information that is only encoded in higher visual areas. 

The present study, by relying on comparisons across the same set of neurons, tackles the question as to whether the representation captured at one point is stronger or less variable than at other point, and most of our discussion rests upon the implicit assumption that the only representation that is of interest to us is the one we have the capacity to measure, the neuronal activity, in contrast to other possible representations such as neuronal internal states.

Although our group has farmacological evidence that qualitatively agrees with the classification results, we have no conclusive evidence that the changes in classifier performance are in any way causally related to the changing regional dependencies. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Representations

% Representations are generally hierarchical and nested \cite{seth2016active}. From single neurons to populations, the representations of sensory stimuly follow modality specific mechanisms \cite{}, and get farther from the primary cortices for more complex stimuli. Taking vision as an example: while angles of light sources are processed in V1, motion is processed in the MT region in the parietal cortex, and object identities in area V4 \cite{deyoe1988concurrent}. The same occurs in the motor domain \cite{hamilton2007motor,fernandes2017episodic}: while simple movements are traced to the M1 area \cite{graziano2016ethological}, complex movement patterns can be encoded in the supplementary motor area \cite{nachev2008functional}. 
%% Colocar imagem da hierarquia
% In the example of vision, the simplest representations are angles of light sources in V1, which resemble independent components of natural scenes \cite{bell1997independent}, making them an efficient representation for natural scenes. Representation of correlated edges, such as angles and contours take place at V2 \cite{ito2004representation, lee2008sparse}. What constitutes these simplest representations, present in the lowest level of the hierarchy, is specific for the modality being discussed, and it doesn't necessarily follow common sense \cite{}. While in the visual domain the simplest cortical representations are straight edges or bars \cite{bell1997independent}, in the motor cortex they are evolutionarily relevant movements like hand-to-mouth \cite{graziano2016ethological}. In the time domain, interoception modulation of interval timing \cite{pollatos2014interoceptive, tomasi2014dissecting}, points bodily states as one basis for interval timing \cite{bueti2011physiological, wittmann2010accumulation}, while other studies 
% They may be unusual basic operations in the sense that they dont f \cite[p.~3-4]{von2012computer}
% In higher levels of the hierarchy, representations develop invariances \cite{}



%The orbitofrontal cortex (OFC) or ventromedial frontal cortex (vmPFC) is one critical structure involved in emotion processing and decision making \cite{bechara2000emotion}. Damage to this structure may impair decision making both in social and personal domains, and is associated with impulsive and disinhibited behavior \cite{berlin2004impulsivity}.


